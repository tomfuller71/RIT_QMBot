{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load the API key from the .env file\n",
    "env_path = Path('../.env')\n",
    "config = dotenv_values(env_path)\n",
    "client = OpenAI(api_key=config['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create description and instructions for the assistant.  The description should be a brief summary of what the bot does and must be less than 512 characters. Its only used to display in the openai portal - not too important.\n",
    "\n",
    "The 'instructructions' however are critical.  They are where 'prompt engineering' come in to find the best instuctions to give to the bot to make it work how you want.  Just as it's easier to format and edit the intructions text, they are stored in a separate file 'Data/tutor_prompt.md' and loaded from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"A Chemistry Tutor bot specializing in Quantum Chemistry, utilizing the textbook QUANTUM CHEMISTRY SECOND EDITION by Donald A. McQuarrie. Bot will assist students after they have completed exams questions by providing feedback and guidance on where their answers could be improved.\"\n",
    "\n",
    "print(f\"Description length: {len(description)}.\")\n",
    "assert len(description) <= 512, \"Description must be less than 512 characters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the prompt file\n",
    "prompt_path = Path('Data/tutor_prompt.md')\n",
    "\n",
    "# Read the prompt from the file\n",
    "with open(prompt_path, 'r') as file:\n",
    "    instructions = file.read()\n",
    "    print(f\"Instructions length: {len(instructions)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now  need to create an openai \"Assistant\".  Our api call returns a Assistants object that contains a unique id for that assistant.  We use this id when dispatching messages to the assistent.  As with files uploaded to openai - we only need to do this once. We need to associate the vector store with the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tutor agent using the beta OpenAI Assistants API\n",
    "tutor_agent = client.beta.assistants.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    name=\"QM Professor Tutor\",\n",
    "    description=description,\n",
    "    instructions=instructions,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add knowledge to our assistant in the form of files that the assistant can search using their \"file_search\" tool.  Upload the knowledge base to openai using their api.  The upload returns a open ai [file object](https://platform.openai.com/docs/api-reference/files) that has a unique \"id\" attribute.  Once we have uploaded once we can afterwards just use this unique id attribute when creating an a vector store from these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the knowledge file\n",
    "knowledge_file_path = Path('KnowledgeBase/QUANTUM_CHEMISTRY_SECOND_EDITION.pdf')\n",
    "\n",
    "# Upload the knowledge file to OpenAI\n",
    "with open(knowledge_file_path, 'rb') as content_file:\n",
    "    openai_file_obj = client.files.create(\n",
    "        purpose='assistants',\n",
    "        file=content_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a [Vector Store](https://platform.openai.com/docs/assistants/tools/file-search/vector-stores) to hold an embedding of the files we want in our knowledge base for the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store\n",
    "vector_store = client.beta.vector_stores.create(name='quantum-chemistry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing and embedding the file into the store is an async process that can take some time to best to poll for success before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_file = client.beta.vector_stores.files.create_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=openai_file_obj.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to update our assistant to give it the id of the newly embedded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutor_agent = client.beta.assistants.update(\n",
    "    assistant_id=tutor_agent.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the secret openai ids into the .env file so they won't leak accidentally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the tutor agent id and the vector store id  to the .env file\n",
    "config['TUTOR_AGENT_ID'] = tutor_agent.id\n",
    "config['VECTOR_STORE_ID'] = vector_store.id\n",
    "config['KNOWLEDGE_FILE_ID'] = openai_file_obj.id\n",
    "\n",
    "with open(env_path, 'w') as file:\n",
    "    for key, value in config.items():\n",
    "        file.write(f\"{key}={value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
