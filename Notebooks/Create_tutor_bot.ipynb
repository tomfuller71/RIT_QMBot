{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load the API key from the .env file\n",
    "env_path = Path('../.env')\n",
    "config = dotenv_values(env_path)\n",
    "client = OpenAI(api_key=config['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create description and instructions for the assistant.  The description should be a brief summary of what the bot does and must be less than 512 characters. Its only used to display in the openai portal - not too important.\n",
    "\n",
    "The 'instructions' however are critical.  They are where 'prompt engineering' come in to find the best instuctions to give to the bot to make it work how you want.  Just as it's easier to format and edit the intructions text, they are stored in a separate file 'Data/tutor_prompt.md' and loaded from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description length: 280.\n"
     ]
    }
   ],
   "source": [
    "description = \"A Chemistry Tutor bot specializing in Quantum Chemistry, utilizing the textbook QUANTUM CHEMISTRY SECOND EDITION by Donald A. McQuarrie. Bot will assist students after they have completed exams questions by providing feedback and guidance on where their answers could be improved.\"\n",
    "\n",
    "bot_name = \"Chemistry Tutor Toy_1\"\n",
    "\n",
    "print(f\"Description length: {len(description)}.\")\n",
    "assert len(description) <= 512, \"Description must be less than 512 characters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the instructions we want to use for our assistant from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions length: 9549.\n"
     ]
    }
   ],
   "source": [
    "#Path to the prompt file\n",
    "prompt_path = Path('../Data/tutor_prompt.md')\n",
    "\n",
    "# Read the prompt from the file\n",
    "with open(prompt_path, 'r') as file:\n",
    "    instructions = file.read()\n",
    "    print(f\"Instructions length: {len(instructions)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now  need to create an openai \"Assistant\".  Our api call returns a Assistants object that contains a unique id for that assistant.  We need this id when dispatching any POST/GET to the OpenAI API endpoints.\n",
    "\n",
    "The 'temperature' parameter controls the randomness and creativity of the generated response where 0 would be virtually deterministic and not very creative, whereas the max of 2 could be very \"creative\".\n",
    "\n",
    "You also have to decide on what model you want to use.  Currently (May 2024) \"gpt-4-turbo\" is OpenAI's best model.  But it is also the most [expensive](https://openai.com/api/pricing/).  For very basic bots it may be worth using 'gpt-3.5-turbo' as it is 20 times cheaper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model and temperature for the tutor agent\n",
    "model = \"gpt-4o\"\n",
    "temperature = 0.1\n",
    "\n",
    "# Create the tutor agent using the beta OpenAI Assistants API\n",
    "tutor_agent = client.beta.assistants.create(\n",
    "    model=model,\n",
    "    name=bot_name,\n",
    "    description=description,\n",
    "    instructions=instructions,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    temperature=temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add knowledge to our assistant in the form of files that the assistant can search using their \"file_search\" tool.  The OpenAI API automatically parses, chunks and then stores a representation of the knowledge base in a [vector store](https://platform.openai.com/docs/assistants/tools/file-search/vector-stores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 Knowledge Files.\n"
     ]
    }
   ],
   "source": [
    "# Generate Paths to any files in the KnowLedgeBase directory\n",
    "base_path = Path('../KnowledgeBase')\n",
    "files = os.listdir(base_path)\n",
    "file_paths = [Path(base_path, file) for file in files]\n",
    "print(f\"Found {len(file_paths)} Knowledge Files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store caled \"Tutor_Bot_Test\"\n",
    "vector_store = client.beta.vector_stores.create(name=bot_name + \"_Vector_Store\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store, and wait for the operation to complete\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can see the status of the file batch and the number of files that were added to the vector store\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to update our assistant to associate the 'Assistant' and the vector store and enable the assistant to use the [file_search](https://platform.openai.com/docs/assistants/tools/file-search) tool.  The 'Assistant' will determine itself automatically based on its instructions and any messages send to it whether to use \"file_search\" to augment its context will information retrieved from it's knowledge base (the vector store)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutor_agent = client.beta.assistants.update(\n",
    "    assistant_id=tutor_agent.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the secret openai ids into the .env file so they won't leak accidentally - they will be retrieved from the env file and used by our `Use_tutor_bot.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the tutor agent id and the vector store id  to the .env file\n",
    "config['TUTOR_AGENT_ID'] = tutor_agent.id\n",
    "config['VECTOR_STORE_ID'] = vector_store.id\n",
    "\n",
    "with open(env_path, 'w') as file:\n",
    "    for key, value in config.items():\n",
    "        file.write(f\"{key}={value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
